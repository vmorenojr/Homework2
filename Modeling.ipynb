{"cells":[{"cell_type":"markdown","source":[" ### Introduction to Data Science - 2019.2\n","\n"," ### Valter Moreno"],"metadata":{}},{"cell_type":"markdown","source":[" ### Homework 2: Predicting Schools Performance"],"metadata":{}},{"cell_type":"markdown","source":[" ### Data"],"metadata":{}},{"cell_type":"markdown","source":[" The data for this project was provided in four csv files containing information on shools in SÃ£o Paulo metropolitan region.\n"," They were cleaned, transformed and saved in the Schools.csv file."],"metadata":{}},{"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","from sklearn import tree\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.model_selection import validation_curve\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","\n","pd.set_option('display.float_format', lambda x: '%.2f' % x)\n","sns.set(style=\"darkgrid\")\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Reading the data into a dataframe\n","\n","schools = pd.read_csv('Data/Schools.csv', encoding='utf-8')\n","schools.head()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" As Scikit Learn expects continuous predictors, I will convert\n"," the INSE_CL to a set of dummy variables."],"metadata":{}},{"source":["dummies = pd.get_dummies(schools.INSE_CL, prefix='INSE_CL')\n","\n","schools.drop(['CD_ESCOLA', 'INSE_CL'], axis=1, inplace=True)\n","schools = schools.merge(dummies, left_index=True, right_index=True)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Splitting the data into training and testing datasets\n","\n","train, test = train_test_split(schools, test_size=0.2)\n","\n","X = train.drop('ENEM', axis=1)\n","y = train.ENEM\n","\n","Xtest = test.drop('ENEM', axis=1)\n","ytest = test.ENEM\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" I will test several decision tree options to predict the classifiction\n"," of a school in ENEM 2015. All features in the 'sxhools' dataframe\n"," will be used as predictors.\n","\n"," I will use cross-folding with 5 splits to train and test the model."],"metadata":{}},{"cell_type":"markdown","source":["### Single decision tree"],"metadata":{}},{"source":["crossvalidation = KFold(n_splits=5, \n","                        shuffle=True,\n","                        random_state=1)\n","\n","for depth in range(1,10):\n","    tree_classifier = tree.DecisionTreeClassifier(\n","        max_depth=depth, random_state=0)\n","    if tree_classifier.fit(X,y).tree_.max_depth < depth:\n","        break\n","    score = np.mean(cross_val_score(tree_classifier, \n","                                    X, y, \n","                                    scoring='accuracy', \n","                                    cv=crossvalidation))\n","    print('Depth: %i Accuracy: %.3f' % (depth,score))\n","    "],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" Based on the accuracy results, a tree with 6 splits seems to be\n"," the best option.\n","\n"," Nevertheless, to get an effective reduction and simplifiction,\n"," I will set the min_samples_split to 30 and avoid terminal leaves\n"," that are too small by setting min_samples_leaf to 10."],"metadata":{}},{"source":["tree_classifier = tree.DecisionTreeClassifier(\n","    min_samples_split=30, \n","    min_samples_leaf=10, \n","    random_state=0)\n","tree_classifier.fit(X,y)\n","score = np.mean(cross_val_score(tree_classifier, X, y, \n","                                scoring='accuracy', \n","                                cv=crossvalidation))\n","print('Accuracy: %.3f' % score)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" I will predict the values in the test dataset now."],"metadata":{}},{"source":["tree_accuracy = tree_classifier.score(Xtest, ytest)\n","\n","print('Accuracy on test data:', tree_accuracy)\n","print('Confusion matrix:')\n","print(confusion_matrix(ytest, tree_classifier.predict(Xtest)))\n","    "],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["### Bagging"],"metadata":{}},{"source":["tree_classifier = DecisionTreeClassifier(random_state=0)\n","bagging = BaggingClassifier(tree_classifier, \n","                            max_samples=0.7, \n","                            max_features=0.7, \n","                            n_estimators=300)\n","scores = np.mean(cross_val_score(bagging, X, y, \n","                                 scoring='accuracy', \n","                                 cv=crossvalidation))\n","print ('Accuracy: %.3f' % scores)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The accuracy of the model for the training set was higher than\n"," that of the single decision tree.\n","\n"," I will vary the number of models in the tree to identify the\n"," the optimum value for the hyperparameter."],"metadata":{}},{"source":["param_range = [10, 50, 100, 200, 300, 500, 800, 1000, 1200, 1500, 1800]\n","train_scores, test_scores = validation_curve(bagging, X, y,\n","                                  'n_estimators', \n","                                  param_range=param_range, \n","                                  cv=crossvalidation, \n","                                  scoring='accuracy')\n","mean_test_scores = np.mean(test_scores, axis=1)\n","\n","g = sns.relplot(x='Models', y='Accuracy',\n","                kind=\"line\",\n","                data=pd.DataFrame({'Models': param_range,\n","                                   'Accuracy': mean_test_scores}))\n","g.fig.autofmt_xdate()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The chart indicates that an adequate performance can be obtained\n"," with 300 models. I will predict the values in the test dataset\n"," using this value."],"metadata":{}},{"source":["bagging = bagging.fit(X,y)\n","bagging_accuracy = bagging.score(Xtest, ytest)\n","print('Accuracy on test data: %.3f' % bagging_accuracy)\n","print('Confusion matrix:')\n","print(confusion_matrix(ytest, bagging.predict(Xtest)))\n","    "],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["### Random Forest"],"metadata":{}},{"source":["RF_cls = RandomForestClassifier(n_estimators=300,\n","                               random_state=1)\n","score = np.mean(cross_val_score(RF_cls, X, y, \n","                                scoring='accuracy', \n","                                cv=crossvalidation))\n","print('Accuracy: %.3f' % score) \n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The accuracy of the random forest was lower than that obtained\n"," with the previous model. I will repeat the analysis varying the\n"," number of models."],"metadata":{}},{"source":["train_scores, test_scores = validation_curve(RF_cls, X, y,\n","                                             'n_estimators',\n","                                             param_range=param_range,\n","                                             cv=crossvalidation, \n","                                             scoring='accuracy')\n","mean_test_scores = np.mean(test_scores, axis=1)\n","\n","g = sns.relplot(x='Models', y='Accuracy',\n","                kind=\"line\",\n","                data=pd.DataFrame({'Models': param_range,\n","                                   'Accuracy': mean_test_scores}))\n","g.fig.autofmt_xdate()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The chart shows that the best trade-off is to set the number of\n"," models to 300. I will search for a combination of hyperparameters to try to\n"," increase the accuracy of the model."],"metadata":{}},{"source":["search_grid = {'n_estimators':[50, 100, 300],\n","               'max_features': [X.shape[1]//3, 'sqrt', 'log2', 'auto'], \n","               'min_samples_leaf': [1, 10, 30]}\n","\n","search_func = GridSearchCV(estimator=RF_cls,\n","                            param_grid=search_grid,\n","                            scoring='accuracy',\n","                            cv=crossvalidation)\n","search_func.fit(X, y)\n","best_params = search_func.best_params_\n","best_score = search_func.best_score_\n","print('Best parameters: %s' % best_params)\n","print('Best accuracy: %.3f' % best_score)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The best combination of parameters generated a higher accuracy value.\n"," I will use it to predict the values in the test dataset."],"metadata":{}},{"source":["RF_cls = RandomForestClassifier(max_features=50,\n","                                min_samples_leaf=1,\n","                                n_estimators=100,\n","                                random_state=1)\n","RF_cls = RF_cls.fit(X,y)\n","rf_accuracy = RF_cls.score(Xtest, ytest)\n","\n","print('Accuracy on test data: %.3f' % rf_accuracy)\n","print('Confusion matrix:')\n","print(confusion_matrix(ytest, RF_cls.predict(Xtest)))\n","    "],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The new model showed a higher accuracy value than the previous ones."],"metadata":{}},{"cell_type":"markdown","source":["### Boosting\n"," In this last step, I will use two boosting applications, adaboost\n"," and gradient boosting machines to predict a school's classification\n"," in ENEM 2015."],"metadata":{}},{"cell_type":"markdown","source":["#### Adaboost"],"metadata":{}},{"source":["ada = AdaBoostClassifier(n_estimators=1000, \n","                         learning_rate=0.01, \n","                         base_estimator=DecisionTreeClassifier(max_depth=1),\n","                         random_state=1)\n","crossvalidation = KFold(n_splits=5, shuffle=True, \n","                        random_state=1)\n","score = np.mean(cross_val_score(ada, X, y, \n","                                scoring='accuracy', \n","                                cv=crossvalidation))\n","print('Accuracy: %.3f' % score)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The accuracy of the adaboost model was reasonably low. I will\n"," explore variations in the number of estimators."],"metadata":{}},{"source":["param_range = [100, 500, 1000, 1250, 1500, 2000, 2500]\n","train_scores, test_scores = validation_curve(ada, X, y,\n","                                             'n_estimators',\n","                                             param_range=param_range,\n","                                             cv=crossvalidation, \n","                                             scoring='accuracy')\n","mean_test_scores = np.mean(test_scores, axis=1)\n","\n","g = sns.relplot(x='Models', y='Accuracy',\n","                kind=\"line\",\n","                data=pd.DataFrame({'Models': param_range,\n","                                   'Accuracy': mean_test_scores}))\n","g.fig.autofmt_xdate()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The chart indicates that the best accuracy is obtained around 2000\n"," estimators. I will search for a better combination of number of\n"," estimators and learning rate to further increase the accuracy of\n"," the model."],"metadata":{}},{"source":["search_grid = {'n_estimators': [15000, 1800, 2000, 2200, 1500],\n","               'learning_rate': [0.005, 0.01, 0.015, 0.02]}\n","\n","search_func = GridSearchCV(estimator=ada,\n","                           param_grid=search_grid,\n","                           scoring='accuracy',\n","                           cv=crossvalidation)\n","search_func.fit(X, y)\n","best_params = search_func.best_params_\n","best_score = search_func.best_score_\n","print('Best parameters: %s' % best_params)\n","print('Best accuracy: %.3f' % best_score)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The best combination of parameters generated a higher accuracy value.\n"," I will use it to predict the values in the test dataset."],"metadata":{}},{"source":["ada = AdaBoostClassifier(n_estimators=1800, \n","                         learning_rate=0.01, \n","                         base_estimator=DecisionTreeClassifier(max_depth=1),\n","                         random_state=1)\n","ada = ada.fit(X,y)\n","ada_accuracy = ada.score(Xtest, ytest)\n","\n","print('Accuracy on test data: %.3f' % ada_accuracy)\n","print('Confusion matrix:')\n","print(confusion_matrix(ytest, ada.predict(Xtest)))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["#### Gradient Boosting Classifier"],"metadata":{}},{"source":["crossvalidation = KFold(n_splits=5, \n","                        shuffle=True, \n","                        random_state=1)\n","\n","GBC = GradientBoostingClassifier(n_estimators=300, \n","                                 subsample=1.0, \n","                                 max_depth=3, \n","                                 learning_rate=0.1, \n","                                 random_state=1)\n","score = np.mean(cross_val_score(GBC, X, y, \n","                                scoring='accuracy', \n","                                cv=crossvalidation))\n","print('Accuracy: %.3f' % score)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" I will explore combinations of the parameters of the model to\n"," try to improve the accuracy."],"metadata":{}},{"source":["search_grid =  {'subsample': [1.0, 0.9], \n","                'max_depth': [2, 3, 5], \n","                'n_estimators': [250, 500 , 1000, 1500]}\n","search_func = GridSearchCV(estimator=GBC,\n","                           param_grid=search_grid,\n","                           scoring='accuracy',\n","                           learning_rate=[0.1, 0.2, 0.3],\n","                           cv=crossvalidation)\n","search_func.fit(X,y)\n","\n","best_params = search_func.best_params_\n","best_score = abs(search_func.best_score_)\n","print('Best parameters: %s' % best_params)\n","print('Best mean squared error: %.3f' % best_score)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The best combination of parameters will be used to predict the\n"," classification in ENEM for the schools in the test dataset."],"metadata":{}},{"source":["GBC = GradientBoostingClassifier(n_estimators=500, \n","                                 subsample=0.9, \n","                                 max_depth=2, \n","                                 learning_rate=0.1, \n","                                 random_state=1)\n","GBC = GBC.fit(X,y)\n","gb_accuracy = GBC.score(Xtest, ytest)\n","\n","print('Accuracy on test data: %.3f' % gb_accuracy)\n","print('Confusion matrix:')\n","print(confusion_matrix(ytest, GBC.predict(Xtest)))\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["## Conclusion\n"," Here are the accuracy for each of the models previously fitted to\n"," the test data:\n","  The best model with the highest accuracy obtained was"],"metadata":{}},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}